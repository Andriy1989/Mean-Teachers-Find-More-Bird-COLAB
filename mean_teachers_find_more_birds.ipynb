{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "mean-teachers-find-more-birds.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 19405.783445,
      "end_time": "2021-02-04T15:44:24.896347",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2021-02-04T10:20:59.112902",
      "version": "2.2.2"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqMOwuZelgdM",
        "outputId": "2a69259d-e91b-415e-cc43-896253a6a5cb"
      },
      "source": [
        "import os\r\n",
        "\r\n",
        "COLAB=False\r\n",
        "models_path=''\r\n",
        "\r\n",
        "if not os.path.exists('../input/rfcx-species-audio-detection'):# Let's check if we use kaggle notebook\r\n",
        "    COLAB=True\r\n",
        "    import gc\r\n",
        "    from google.colab import drive\r\n",
        "    drive.mount('/content/drive')# You must grant COLAB access to your Google Drive\r\n",
        "\r\n",
        "\r\n",
        "    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\r\n",
        "    #fs = gcsfs.GCSFileSystem(project='gs://kds-5c677f76ce55440722b2a474a5492faa70847c05a8f5d722f5a37fe')\r\n",
        "\r\n",
        "    GCS_DS_PATH = 'gs://kds-5c677f76ce55440722b2a474a5492faa70847c05a8f5d722f5a37feb'# \r\n",
        "    #This is a path to a dataset that changes over time, so you need to constantly update it. To update the path just run the code: \r\n",
        "    #GCS_DS_PATH = KaggleDatasets (). Get_gcs_path ()\r\n",
        "    #print (GCS_DS_PATH)\r\n",
        "    models_path='/content/drive/MyDrive/Models/'# I created a folder called Models on my Google Drive and put the kaggle.json file in it\r\n",
        "else:\r\n",
        "    from kaggle_datasets import KaggleDatasets\r\n",
        "    GCS_DS_PATH = KaggleDatasets().get_gcs_path('rfcx-species-audio-detection')\r\n",
        "    print (GCS_DS_PATH)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NC1SeGc5lgaW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1373a9c-44f8-4730-c2b4-473f32fdcd51"
      },
      "source": [
        "if COLAB:# Prepare the kaggle.json file for use \r\n",
        "    from google.colab import files\r\n",
        "    if not os.path.exists('/.kaggle/kaggle.json'):\r\n",
        "        !mkdir ~/.kaggle\r\n",
        "        if not os.path.exists('/content/drive/My Drive/Models/kaggle.json'):\r\n",
        "            files.upload()\r\n",
        "            !cp kaggle.json ~/.kaggle/\r\n",
        "        else:\r\n",
        "            !cp '/content/drive/My Drive/Models/kaggle.json' ~/.kaggle/  \r\n",
        "        !chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCv7fR9IlgXt"
      },
      "source": [
        "import numpy as np\r\n",
        "import os\r\n",
        "import time\r\n",
        "\r\n",
        "from torchvision import datasets, transforms\r\n"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAg83gt0lgVH"
      },
      "source": [
        ""
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ID281mcvlgGv"
      },
      "source": [
        ""
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0IqhmIRlWZb"
      },
      "source": [
        "# Introduction\n",
        "I wanted to share something that worked pretty well for me early on in this competition. The idea comes from a [2018 paper](https://arxiv.org/pdf/1703.01780.pdf) titled *Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results* by Antti Tarvainen and Harri Valpola. \n",
        "\n",
        "### Mean Teacher\n",
        "Biefly, the idea is to use two models. A student model with weights trained the standard way, using backprop. And a teacher model with weights that are an exponential moving average of the student's weights. The teacher is the *mean* of the student \\*ba dum tss\\*. The student is then trained using two different losses, a standard classification loss and a consistency loss that penalizes student predictions that deviate from the teaher's. \n",
        "\n",
        "![](https://raw.githubusercontent.com/CuriousAI/mean-teacher/master/mean_teacher.png)\n",
        "\n",
        "Mean teachers are useful in a semi-supervised context where we have both labeled and unlabeled samples. The consistency loss on the unlabeled samples acts as a form of regularization and helps the model generalize better. As an added bonus the final teacher model is a temporal ensemble which tends to perform better than the results at the end of a single epoch. \n",
        "\n",
        "### Missing Labels\n",
        "As a few others have pointed out, there are a lot of missing labels. If we were to randomly sample a segment from the training data, we might consider it completely unlabeled rather than rely on the provided labels. We'll train our mean teacher model(s) on two classes of data, carefully selected positive samples and randomly selected unlabeled samples. The classification loss won't apply to the unlabeled samples. \n",
        "\n",
        "![](https://www.googleapis.com/download/storage/v1/b/kaggle-forum-message-attachments/o/inbox%2F4704212%2F9ca088bb386abf7114543c019c1d8a5f%2Ffig.png?generation=1609892974092435&alt=media)\n",
        "\n",
        "*Thanks to [shinmura0](https://www.kaggle.com/shinmurashinmura) for the great visualization!*\n",
        "\n",
        "### Results\n",
        "For me, mean teacher worked a good bit better than baseline models with similar configurations. \n",
        "\n",
        "|                                         | Baseline | Mean Teacher |\n",
        "|-----------------------------------------|----------|--------------|\n",
        "| Well Tuned, 5 fold, from my local setup | 0.847        | **0.865**            |\n",
        "| Single fold Expt1 on Kaggle                   | 0.592**        | **0.786**            |\n",
        "| Single fold Expt2 on Kaggle                   | 0.826        | **0.830**            |\n",
        "| 5 Fold on Kaggle                        | ?        | ?            |\n",
        "\n",
        "\\*\\* I might have accidentally sabatoged this run."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPZn66xElWZg"
      },
      "source": [
        "!pip -q install --upgrade pip\n",
        "!pip -q install timm\n",
        "!pip -q install torchlibrosa\n",
        "!pip -q install audiomentations\n",
        "!pip -q install contextlib2\n",
        "!pip -q install fsspec\n",
        "!pip -q install gcsfs"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTJWjHiFlWZh"
      },
      "source": [
        "import audiomentations as A\n",
        "import os, time, librosa, random\n",
        "from functools import partial\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from timm.models import resnet34d\n",
        "from torchlibrosa.stft import Spectrogram, LogmelFilterBank\n",
        "from torchlibrosa.augmentation import SpecAugmentation\n",
        "from tqdm import tqdm\n",
        "import soundfile as sf\n",
        "import gcsfs\n",
        "import contextlib\n",
        "from contextlib import ExitStack as nullcontext\n",
        "\n",
        "#contextlib.nullcontext"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BI3CbPxslWZi"
      },
      "source": [
        "# Config\n",
        "We'll start by setting up some global config variable that we'll access later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0yuabcrle6R"
      },
      "source": [
        ""
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJlljywLlWZj"
      },
      "source": [
        "# Global Vars\n",
        "NO_LABEL = -1\n",
        "NUM_CLASSES = 24\n",
        "\n",
        "\n",
        "class config:\n",
        "    seed = 42\n",
        "    device = \"cuda:0\"\n",
        "    \n",
        "    train_tp_csv = GCS_DS_PATH+'/train_tp.csv'\n",
        "    test_csv = GCS_DS_PATH+'/sample_submission.csv'\n",
        "    save_path = models_path\n",
        "    \n",
        "    encoder = resnet34d\n",
        "    encoder_features = 512\n",
        "    \n",
        "    percent_unlabeled = 1.0\n",
        "    consistency_weight = 100.0\n",
        "    consistency_rampup = 1000 # 6 epochs\n",
        "    ema_decay = 0.995\n",
        "    positive_weight = 2.0\n",
        "    \n",
        "    lr = 1e-3\n",
        "    epochs = 25\n",
        "    batch_size = 32\n",
        "    num_workers = 4\n",
        "    train_5_folds = True\n",
        "    \n",
        "    period = 6 # 6 second clips\n",
        "    step = 1\n",
        "    model_params = {\n",
        "        'sample_rate': 48000,\n",
        "        'window_size': 2048,\n",
        "        'hop_size': 512,\n",
        "        'mel_bins': 384,\n",
        "        'fmin': 20,\n",
        "        'fmax': 48000 // 2,\n",
        "        'classes_num': NUM_CLASSES\n",
        "    }\n",
        "    \n",
        "    augmenter = A.Compose([\n",
        "        A.AddGaussianNoise(p=0.33, max_amplitude=0.02),\n",
        "        A.AddGaussianSNR(p=0.33),\n",
        "        A.FrequencyMask(min_frequency_band=0.01,  max_frequency_band=0.25, p=0.33),\n",
        "        A.TimeMask(min_band_part=0.01, max_band_part=0.25, p=0.33),\n",
        "        A.Gain(p=0.33)\n",
        "    ])\n"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5pIq_xelWZj"
      },
      "source": [
        "## Utils - Not much interesting going on here.\n",
        "\n",
        "def get_n_fold_df(csv_path, folds=5):\n",
        "    df = pd.read_csv(csv_path)\n",
        "    df_group = df.groupby(\"recording_id\")[[\"species_id\"]].first().reset_index()\n",
        "    df_group = df_group.sample(frac=1, random_state=config.seed).reset_index(drop=True)\n",
        "    df_group.loc[:, 'fold'] = -1\n",
        "\n",
        "    X = df_group[\"recording_id\"].values\n",
        "    y = df_group[\"species_id\"].values\n",
        "\n",
        "    kfold = StratifiedKFold(n_splits=folds, random_state=config.seed)\n",
        "    for fold, (t_idx, v_idx) in enumerate(kfold.split(X, y)):\n",
        "        df_group.loc[v_idx, \"fold\"] = fold\n",
        "\n",
        "    return df.merge(df_group[['recording_id', 'fold']], on=\"recording_id\", how=\"left\")\n",
        "    \n",
        "\n",
        "def init_layer(layer):\n",
        "    nn.init.xavier_uniform_(layer.weight)\n",
        "\n",
        "    if hasattr(layer, \"bias\"):\n",
        "        if layer.bias is not None:\n",
        "            layer.bias.data.fill_(0.)\n",
        "\n",
        "\n",
        "def init_bn(bn):\n",
        "    bn.bias.data.fill_(0.)\n",
        "    bn.weight.data.fill_(1.0)\n",
        "\n",
        "\n",
        "def sigmoid_rampup(current, rampup_length):\n",
        "    \"\"\"Exponential rampup from https://arxiv.org/abs/1610.02242\"\"\"\n",
        "    if rampup_length == 0:\n",
        "        return 1.0\n",
        "    else:\n",
        "        current = np.clip(current, 0.0, rampup_length)\n",
        "        phase = 1.0 - current / rampup_length\n",
        "        return float(np.exp(-5.0 * phase * phase))\n",
        "\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "class MetricMeter(object):\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.y_true = []\n",
        "        self.y_pred = []\n",
        "\n",
        "    def update(self, y_true, y_pred):\n",
        "        try:\n",
        "            self.y_true.extend(y_true.detach().cpu().numpy().tolist())\n",
        "            self.y_pred.extend(torch.sigmoid(y_pred).cpu().detach().numpy().tolist())\n",
        "        except:\n",
        "            print(\"UPDATE FAILURE\")\n",
        "\n",
        "    def update_list(self, y_true, y_pred):\n",
        "        self.y_true.extend(y_true)\n",
        "        self.y_pred.extend(y_pred)\n",
        "\n",
        "    @property\n",
        "    def avg(self):\n",
        "        score_class, weight = lwlrap(np.array(self.y_true), np.array(self.y_pred))\n",
        "        self.score = (score_class * weight).sum()\n",
        "\n",
        "        return self.score\n",
        "    \n",
        "\n",
        "def interpolate(x: torch.Tensor, ratio: int):\n",
        "    \"\"\"Interpolate data in time domain. This is used to compensate the\n",
        "    resolution reduction in downsampling of a CNN.\n",
        "\n",
        "    Args:\n",
        "      x: (batch_size, time_steps, classes_num)\n",
        "      ratio: int, ratio to interpolate\n",
        "    Returns:\n",
        "      upsampled: (batch_size, time_steps * ratio, classes_num)\n",
        "    \"\"\"\n",
        "    (batch_size, time_steps, classes_num) = x.shape\n",
        "    upsampled = x[:, :, None, :].repeat(1, 1, ratio, 1)\n",
        "    upsampled = upsampled.reshape(batch_size, time_steps * ratio, classes_num)\n",
        "    return upsampled\n",
        "\n",
        "def _one_sample_positive_class_precisions(scores, truth):\n",
        "    num_classes = scores.shape[0]\n",
        "    pos_class_indices = np.flatnonzero(truth > 0)\n",
        "\n",
        "    if not len(pos_class_indices):\n",
        "        return pos_class_indices, np.zeros(0)\n",
        "\n",
        "    retrieved_classes = np.argsort(scores)[::-1]\n",
        "\n",
        "    class_rankings = np.zeros(num_classes, dtype=np.int)\n",
        "    class_rankings[retrieved_classes] = range(num_classes)\n",
        "\n",
        "    retrieved_class_true = np.zeros(num_classes, dtype=np.bool)\n",
        "    retrieved_class_true[class_rankings[pos_class_indices]] = True\n",
        "\n",
        "    retrieved_cumulative_hits = np.cumsum(retrieved_class_true)\n",
        "\n",
        "    precision_at_hits = (\n",
        "            retrieved_cumulative_hits[class_rankings[pos_class_indices]] /\n",
        "            (1 + class_rankings[pos_class_indices].astype(np.float)))\n",
        "    return pos_class_indices, precision_at_hits\n",
        "\n",
        "\n",
        "def lwlrap(truth, scores):\n",
        "    assert truth.shape == scores.shape\n",
        "    num_samples, num_classes = scores.shape\n",
        "    precisions_for_samples_by_classes = np.zeros((num_samples, num_classes))\n",
        "    for sample_num in range(num_samples):\n",
        "        pos_class_indices, precision_at_hits = _one_sample_positive_class_precisions(scores[sample_num, :],\n",
        "                                                                                     truth[sample_num, :])\n",
        "        precisions_for_samples_by_classes[sample_num, pos_class_indices] = precision_at_hits\n",
        "\n",
        "    labels_per_class = np.sum(truth > 0, axis=0)\n",
        "    weight_per_class = labels_per_class / float(np.sum(labels_per_class))\n",
        "\n",
        "    per_class_lwlrap = (np.sum(precisions_for_samples_by_classes, axis=0) /\n",
        "                        np.maximum(1, labels_per_class))\n",
        "    return per_class_lwlrap, weight_per_class\n",
        "\n",
        "\n",
        "def pretty_print_metrics(fold, epoch, optimizer, train_loss_metrics, val_loss_metrics):\n",
        "    print(f\"\"\"\n",
        "    {time.ctime()} \\n\n",
        "    Fold:{fold}, Epoch:{epoch}, LR:{optimizer.param_groups[0]['lr']:.7}, Cons. Weight: {train_loss_metrics['consistency_weight']}\\n\n",
        "    --------------------------------------------------------\n",
        "    Metric:              Train    |   Val\n",
        "    --------------------------------------------------------\n",
        "    Loss:                {train_loss_metrics['loss']:0.4f}   |   {val_loss_metrics['loss']:0.4f}\\n\n",
        "    LWLRAP:              {train_loss_metrics['lwlrap']:0.4f}   |   {val_loss_metrics['lwlrap']:0.4f}\\n\n",
        "    Class Loss:          {train_loss_metrics['class_loss']:0.4f}   |   {val_loss_metrics['class_loss']:0.4f}\\n\n",
        "    Consistency Loss:    {train_loss_metrics['consistency_loss']:0.4f}   |   {val_loss_metrics['consistency_loss']:0.4f}\\n\n",
        "    --------------------------------------------------------\\n\n",
        "    \"\"\")\n",
        "    \n",
        "\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, df, data_path, period=10, step=1):\n",
        "        self.data_path = data_path\n",
        "        self.period = period\n",
        "        self.step = step\n",
        "        self.recording_ids = list(df[\"recording_id\"].unique())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.recording_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        recording_id = self.recording_ids[idx]\n",
        "\n",
        "\n",
        "        fs = gcsfs.GCSFileSystem()\n",
        "        with fs.open(f\"{self.data_path}/{recording_id}.flac\", 'rb') as f:\n",
        "          y, sr = sf.read(f)\n",
        "\n",
        "        len_y = len(y)\n",
        "        effective_length = sr * self.period\n",
        "        effective_step = sr * self.step\n",
        "\n",
        "        y_ = []\n",
        "        i = 0\n",
        "        while i+effective_length <= len_y:\n",
        "            y__ = y[i:i + effective_length]\n",
        "\n",
        "            y_.append(y__)\n",
        "            i = i + effective_step\n",
        "\n",
        "        y = np.stack(y_)\n",
        "\n",
        "        label = np.zeros(NUM_CLASSES, dtype='f')\n",
        "\n",
        "        return {\n",
        "            \"waveform\": y,\n",
        "            \"target\": torch.tensor(label, dtype=torch.float),\n",
        "            \"id\": recording_id\n",
        "        }\n",
        "\n",
        "\n",
        "def predict_on_test(model, test_loader):\n",
        "    model.eval()\n",
        "    pred_list = []\n",
        "    id_list = []\n",
        "    with torch.no_grad():\n",
        "        t = tqdm(test_loader)\n",
        "        for i, sample in enumerate(t):\n",
        "            input = sample[\"waveform\"].to(config.device)\n",
        "            bs, seq, w = input.shape\n",
        "            input = input.reshape(bs * seq, w)\n",
        "            id = sample[\"id\"]\n",
        "            output, _ = model(input)\n",
        "            output = output.reshape(bs, seq, -1)\n",
        "            output, _ = torch.max(output, dim=1)\n",
        "            \n",
        "            output = output.cpu().detach().numpy().tolist()\n",
        "            pred_list.extend(output)\n",
        "            id_list.extend(id)\n",
        "\n",
        "    return pred_list, id_list"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tdj2jQJlWZk"
      },
      "source": [
        "# Model\n",
        "The model should look pretty familiar if you're using [SED](https://arxiv.org/abs/1912.04761). (Huge thanks to [Hidehisa Arai](https://www.kaggle.com/hidehisaarai1213) and their [SED Notebook](https://www.kaggle.com/hidehisaarai1213/introduction-to-sound-event-detection)!) You could use any model you'd like here. There's just one small tweak we need to make for our mean teacher setup. We need to \"detach\" the teacher's parameters so they aren't updated by the optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Rh0T4TElWZl"
      },
      "source": [
        "class AttentionHead(nn.Module):\n",
        "    \n",
        "    def __init__(self, in_features: int, out_features: int):\n",
        "        super().__init__()\n",
        "        self.conv_attention = nn.Conv1d(in_channels=in_features, \n",
        "                                        out_channels=out_features,\n",
        "                                        kernel_size=1, stride=1, \n",
        "                                        padding=0, bias=True)\n",
        "        self.conv_classes = nn.Conv1d(in_channels=in_features, \n",
        "                                      out_channels=out_features,\n",
        "                                      kernel_size=1, stride=1, \n",
        "                                      padding=0, bias=True)\n",
        "        self.batch_norm_attention = nn.BatchNorm1d(out_features)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        init_layer(self.conv_attention)\n",
        "        init_layer(self.conv_classes)\n",
        "        init_bn(self.batch_norm_attention)\n",
        "\n",
        "    def forward(self, x):\n",
        "        norm_att = torch.softmax(torch.tanh(self.conv_attention(x)), dim=-1)\n",
        "        classes = self.conv_classes(x)\n",
        "        x = torch.sum(norm_att * classes, dim=2)\n",
        "        return x, norm_att, classes\n",
        "\n",
        "\n",
        "class SEDAudioClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, sample_rate, window_size, hop_size, \n",
        "                 mel_bins, fmin, fmax, classes_num):\n",
        "        super().__init__()\n",
        "        self.interpolate_ratio = 32\n",
        "\n",
        "        self.spectrogram_extractor = Spectrogram(n_fft=window_size, \n",
        "                                                 hop_length=hop_size,\n",
        "                                                 win_length=window_size, \n",
        "                                                 window='hann', center=True,\n",
        "                                                 pad_mode='reflect', \n",
        "                                                 freeze_parameters=True)\n",
        "        self.logmel_extractor = LogmelFilterBank(sr=sample_rate, n_fft=window_size,\n",
        "                                                 n_mels=mel_bins, fmin=fmin, \n",
        "                                                 fmax=fmax, ref=1.0, \n",
        "                                                 amin=1e-10, top_db=None, \n",
        "                                                 freeze_parameters=True)\n",
        "\n",
        "        self.batch_norm = nn.BatchNorm2d(mel_bins)\n",
        "        self.encoder = partial(config.encoder, pretrained=True, in_chans=1)()\n",
        "        self.fc = nn.Linear(config.encoder_features, \n",
        "                            config.encoder_features, bias=True)\n",
        "        self.att_head = AttentionHead(config.encoder_features, classes_num)\n",
        "        self.avg_pool = nn.modules.pooling.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        self.init_weight()\n",
        "\n",
        "    def init_weight(self):\n",
        "        init_bn(self.batch_norm)\n",
        "        init_layer(self.fc)\n",
        "        self.att_head.init_weights()\n",
        "\n",
        "    def forward(self, input, spec_aug=False, \n",
        "                mixup_lambda=None, return_encoding=False):\n",
        "        x = self.spectrogram_extractor(input.float())\n",
        "        x = self.logmel_extractor(x)\n",
        "        \n",
        "        x = x.transpose(1, 3)\n",
        "        x = self.batch_norm(x)\n",
        "        x = x.transpose(1, 3)\n",
        "\n",
        "        x = self.encoder.forward_features(x)\n",
        "        x = torch.mean(x, dim=3)\n",
        "        x1 = F.max_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
        "        x2 = F.avg_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
        "        x = x1 + x2\n",
        "\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = x.transpose(1, 2)\n",
        "        x = F.relu_(self.fc(x))\n",
        "        x = x.transpose(1, 2)\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "\n",
        "        (clipwise_output, norm_att, segmentwise_output) = self.att_head(x)\n",
        "        segmentwise_output = segmentwise_output.transpose(1, 2)\n",
        "\n",
        "        framewise_output = interpolate(segmentwise_output, self.interpolate_ratio)\n",
        "        return clipwise_output, framewise_output\n",
        "\n",
        "\n",
        "def get_model(is_mean_teacher=False):\n",
        "    model = SEDAudioClassifier(**config.model_params)\n",
        "    model = model.to(config.device)\n",
        "    \n",
        "    # Detach params for Exponential Moving Average Model (aka the Mean Teacher).\n",
        "    # We'll manually update these params instead of using backprop.\n",
        "    if is_mean_teacher:\n",
        "        for param in model.parameters():\n",
        "            param.detach_()\n",
        "    return model"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bATwi1MlWZl"
      },
      "source": [
        "# Loss Function\n",
        "The loss function has 2 components:\n",
        "\n",
        "1. A classification loss that only applies to labeled samples.\n",
        "2. A consistency loss that applies to all samples. \n",
        "\n",
        "For the consistency loss we'll use the mean square error between the student and teacher predictions. We'll slowly ramp up the influence of the consistency loss since we don't want bad, early predictions having too much influence. \n",
        "\n",
        "Notice that we're weighting the positive samples for the classification loss. This is because we know the positives are correct while we're less sure about the negatives due to the missing labels issue. I found that this works better in practice. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBv6dhO3lWZl"
      },
      "source": [
        "def sigmoid_mse_loss(input_logits, target_logits):\n",
        "    assert input_logits.size() == target_logits.size()\n",
        "    input_softmax = torch.sigmoid(input_logits)\n",
        "    target_softmax = torch.sigmoid(target_logits)\n",
        "    num_classes = input_logits.size()[1]\n",
        "    return F.mse_loss(input_softmax, target_softmax, size_average=False\n",
        "                     ) / num_classes\n",
        "\n",
        "\n",
        "class MeanTeacherLoss(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.positive_weight = torch.ones(\n",
        "            NUM_CLASSES).to(config.device) * config.positive_weight\n",
        "        self.class_criterion = nn.BCEWithLogitsLoss(\n",
        "            reduction='none', pos_weight=self.positive_weight)\n",
        "        self.consistency_criterion = sigmoid_mse_loss\n",
        "\n",
        "    def make_safe(self, pred):\n",
        "        pred = torch.where(torch.isnan(pred), torch.zeros_like(pred), pred)\n",
        "        return torch.where(torch.isinf(pred), torch.zeros_like(pred), pred)\n",
        "        \n",
        "    def get_consistency_weight(self, epoch):\n",
        "        # Consistency ramp-up from https://arxiv.org/abs/1610.02242\n",
        "        return config.consistency_weight * sigmoid_rampup(\n",
        "            epoch, config.consistency_rampup)\n",
        "    \n",
        "    def forward(self, student_pred, teacher_pred, target, classif_weights, epoch):\n",
        "        student_pred = self.make_safe(student_pred)\n",
        "        teacher_pred = self.make_safe(teacher_pred).detach().data\n",
        "\n",
        "        batch_size = len(target)\n",
        "        labeled_batch_size = target.ne(NO_LABEL).all(axis=1).sum().item() + 1e-3\n",
        "\n",
        "        student_classif, student_consistency = student_pred, student_pred\n",
        "        student_class_loss = (self.class_criterion(\n",
        "            student_classif, target) * classif_weights / labeled_batch_size).sum()\n",
        "\n",
        "        consistency_weights = self.get_consistency_weight(epoch)\n",
        "        consistency_loss = consistency_weights * self.consistency_criterion(\n",
        "            student_consistency, teacher_pred) / batch_size\n",
        "        loss = student_class_loss + consistency_loss\n",
        "        return loss, student_class_loss, consistency_loss, consistency_weights"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxK8p9FylWZm"
      },
      "source": [
        "# Data Loader\n",
        "The data loader produces two types of samples:\n",
        "\n",
        "1. Labeled samples with the audio centered in the clip.\n",
        "2. Random unlabeled clips without labels selected from files with at least one true positive label.\n",
        "\n",
        "Each sample contains 2 different inputs, one for the student and one for the teacher. Different augmentations are applied to each input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZSh8unylWZn"
      },
      "source": [
        "class MeanTeacherDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, df, transforms, period=5, \n",
        "                 data_path=GCS_DS_PATH+\"/train\", \n",
        "                 val=False, percent_unlabeled=0.0):\n",
        "        self.period = period\n",
        "        self.transforms = transforms\n",
        "        self.data_path = data_path\n",
        "        self.val = val\n",
        "        self.percent_unlabeled = percent_unlabeled\n",
        "\n",
        "        dfgby = df.groupby(\"recording_id\").agg(lambda x: list(x)).reset_index()\n",
        "        self.recording_ids = dfgby[\"recording_id\"].values\n",
        "        self.species_ids = dfgby[\"species_id\"].values\n",
        "        self.t_mins = dfgby[\"t_min\"].values\n",
        "        self.t_maxs = dfgby[\"t_max\"].values\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(len(self.recording_ids) * (1 + self.percent_unlabeled))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if idx >= len(self.recording_ids):\n",
        "            audio, label, rec_id, sr = self.get_unlabeled_item(idx)\n",
        "            # For unlabeled samples, we zero out the classification loss.\n",
        "            classif_weights = np.zeros(NUM_CLASSES, dtype='f')\n",
        "        else:\n",
        "            audio, label, rec_id, sr = self.get_labeled_item(idx)\n",
        "            classif_weights = np.ones(NUM_CLASSES, dtype='f')\n",
        "\n",
        "        audio_teacher = np.copy(audio)\n",
        "\n",
        "        # The 2 samples fed to the 2 models have should have different augmentations.\n",
        "        audio = self.transforms(samples=audio, sample_rate=sr)\n",
        "        audio_teacher = self.transforms(samples=audio_teacher, sample_rate=sr)\n",
        "        # assert (audio != audio_teacher).any()\n",
        "        \n",
        "        return {\n",
        "            \"waveform\": audio,\n",
        "            \"teacher_waveform\": audio_teacher,\n",
        "            \"target\": torch.tensor(label, dtype=torch.float),\n",
        "            \"classification_weights\": classif_weights,\n",
        "            \"id\": rec_id\n",
        "        }\n",
        "\n",
        "    def get_labeled_item(self, idx):\n",
        "        recording_id = self.recording_ids[idx]\n",
        "        species_id = self.species_ids[idx]\n",
        "        t_min, t_max = self.t_mins[idx], self.t_maxs[idx]\n",
        "\n",
        "        fs = gcsfs.GCSFileSystem()\n",
        "        with fs.open(f\"{self.data_path}/{recording_id}.flac\", 'rb') as f:\n",
        "          rec, sr = sf.read(f)\n",
        "  \n",
        "\n",
        "        len_rec = len(rec)\n",
        "        effective_length = sr * self.period\n",
        "        rint = np.random.randint(len(t_min))\n",
        "        tmin, tmax = round(sr * t_min[rint]), round(sr * t_max[rint])\n",
        "        dur = tmax - tmin\n",
        "        min_dur = min(dur, round(sr * self.period))\n",
        "\n",
        "        center = round((tmin + tmax) / 2)\n",
        "        rand_start = center - effective_length + max(min_dur - dur//2, 0)\n",
        "        if rand_start < 0:\n",
        "            rand_start = 0\n",
        "        rand_end = center - max(min_dur - dur//2, 0)\n",
        "        start = np.random.randint(rand_start, rand_end)\n",
        "        rec = rec[start:start + effective_length]\n",
        "        if len(rec) < effective_length:\n",
        "            new_rec = np.zeros(effective_length, dtype=rec.dtype)\n",
        "            start1 = np.random.randint(effective_length - len(rec))\n",
        "            new_rec[start1:start1 + len(rec)] = rec\n",
        "            rec = new_rec.astype(np.float32)\n",
        "        else:\n",
        "            rec = rec.astype(np.float32)\n",
        "\n",
        "        start_time = start / sr\n",
        "        end_time = (start + effective_length) / sr\n",
        "\n",
        "        label = np.zeros(NUM_CLASSES, dtype='f')\n",
        "\n",
        "        for i in range(len(t_min)):\n",
        "            if (t_min[i] >= start_time) & (t_max[i] <= end_time):\n",
        "                label[species_id[i]] = 1\n",
        "            elif start_time <= ((t_min[i] + t_max[i]) / 2) <= end_time:\n",
        "                label[species_id[i]] = 1\n",
        "\n",
        "        return rec, label, recording_id, sr\n",
        "\n",
        "    def get_unlabeled_item(self, idx, random_sample=False):\n",
        "        real_idx = idx - len(self.recording_ids)\n",
        "        # We want our validation set to be fixed.\n",
        "        if self.val:\n",
        "            rec_id = self.recording_ids[real_idx]\n",
        "        else:\n",
        "            rec_id = random.sample(list(self.recording_ids), 1)[0]\n",
        "        fs = gcsfs.GCSFileSystem()    \n",
        "        with fs.open(f\"{self.data_path}/{rec_id}.flac\", 'rb') as f:\n",
        "          rec, sr = sf.read(f)\n",
        "\n",
        "        effective_length = int(sr * self.period)\n",
        "        max_end = len(rec) - effective_length\n",
        "        if self.val:\n",
        "            # Fixed start for validation. Probaably a better way to do this.\n",
        "            start = int(idx * 16963 % max_end)\n",
        "        else:\n",
        "            start = np.random.randint(0, max_end)\n",
        "        rec = rec[start:(start+effective_length)]\n",
        "        rec = rec.astype(np.float32)\n",
        "\n",
        "        label = np.ones(NUM_CLASSES, dtype='f') * NO_LABEL\n",
        "\n",
        "        return rec, label, rec_id, sr\n",
        "\n",
        "    \n",
        "def get_data_loader(df, is_val=False):\n",
        "    dataset = MeanTeacherDataset(\n",
        "        df=df,\n",
        "        transforms=config.augmenter,\n",
        "        period=config.period,\n",
        "        percent_unlabeled=config.percent_unlabeled\n",
        "    )\n",
        "    return torch.utils.data.DataLoader(\n",
        "        dataset,\n",
        "        batch_size=config.batch_size,\n",
        "        shuffle=not is_val,\n",
        "        drop_last=not is_val,\n",
        "        num_workers=config.num_workers\n",
        "    )"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRQMZHlLlWZn"
      },
      "source": [
        "# Training\n",
        "At the end of each training step we update the teacher weights by averaging in the latest student weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B00htZTUlWZo"
      },
      "source": [
        "# Update teacher to be exponential moving average of student params.\n",
        "def update_teacher_params(student, teacher, alpha, global_step):\n",
        "    # Use the true average until the exponential average is more correct\n",
        "    alpha = min(1 - 1 / (global_step + 1), alpha)\n",
        "    for ema_param, param in zip(teacher.parameters(), student.parameters()):\n",
        "        ema_param.data.mul_(alpha).add_(1 - alpha, param.data)\n",
        "\n",
        "\n",
        "def train_one_epoch(student, mean_teacher, loader, \n",
        "                    criterion, optimizer, scheduler, epoch, is_val=False):\n",
        "    global_step = 0\n",
        "    losses = AverageMeter()\n",
        "    consistency_loss_avg = AverageMeter()\n",
        "    class_loss_avg = AverageMeter()\n",
        "    comp_metric = MetricMeter()\n",
        "    \n",
        "    if is_val:\n",
        "        student.eval()\n",
        "        mean_teacher.eval()\n",
        "        context = torch.no_grad()\n",
        "    else:\n",
        "        student.train()\n",
        "        mean_teacher.train()\n",
        "        context = nullcontext()\n",
        "    \n",
        "    with context:\n",
        "        t = tqdm(loader)\n",
        "        for i, sample in enumerate(t):\n",
        "            student_input = sample['waveform'].to(config.device)\n",
        "            teacher_input = sample['teacher_waveform'].to(config.device)\n",
        "            target = sample['target'].to(config.device)\n",
        "            classif_weights = sample['classification_weights'].to(config.device)\n",
        "            batch_size = len(target)\n",
        "\n",
        "            student_pred, _  = student(student_input)\n",
        "            teacher_pred, _  = mean_teacher(teacher_input)\n",
        "\n",
        "            loss, class_loss, consistency_loss, consistency_weight = criterion(\n",
        "                student_pred, teacher_pred, target, classif_weights, epoch)\n",
        "\n",
        "            if not is_val:\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                update_teacher_params(student, mean_teacher, \n",
        "                                      config.ema_decay, global_step)\n",
        "\n",
        "                scheduler.step()\n",
        "\n",
        "            comp_metric.update(target, student_pred)\n",
        "            losses.update(loss.item(), batch_size)\n",
        "            consistency_loss_avg.update(consistency_loss.item(), batch_size)\n",
        "            class_loss_avg.update(class_loss.item(), batch_size)\n",
        "            global_step += 1\n",
        "\n",
        "            t.set_description(f\"Epoch:{epoch} - Loss:{losses.avg:0.4f}\")\n",
        "        t.close()\n",
        "    return {'lwlrap':comp_metric.avg, \n",
        "            'loss':losses.avg, \n",
        "            'consistency_loss':consistency_loss_avg.avg, \n",
        "            'class_loss':class_loss_avg.avg, \n",
        "            'consistency_weight':consistency_weight}"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeMFPExolWZo"
      },
      "source": [
        "Finally putting everything together..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AV9VF8AWlWZo",
        "outputId": "e781f563-0e9f-4753-ed52-1107559b0b36"
      },
      "source": [
        "def train(df, fold):\n",
        "    train_df = df[df.fold != fold]\n",
        "    val_df = df[df.fold == fold]\n",
        "    train_loader = get_data_loader(train_df)\n",
        "    val_loader = get_data_loader(val_df)\n",
        "\n",
        "    student_model = get_model()\n",
        "    teacher_model = get_model(is_mean_teacher=True)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(student_model.parameters(), lr=config.lr)\n",
        "    num_train_steps = int(len(train_loader) * config.epochs)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "        optimizer, T_max=num_train_steps)\n",
        "    criterion = MeanTeacherLoss()\n",
        "\n",
        "    best_val_metric = -np.inf\n",
        "    val_metrics = []\n",
        "    train_metrics = []\n",
        "    for epoch in range(0, config.epochs):\n",
        "        train_loss_metrics = train_one_epoch(\n",
        "            student_model, teacher_model, train_loader, \n",
        "            criterion, optimizer, scheduler, epoch)\n",
        "        val_loss_metrics = train_one_epoch(\n",
        "            student_model, teacher_model, val_loader, \n",
        "            criterion, optimizer, scheduler, epoch, is_val=True)\n",
        "\n",
        "        train_metrics.append(train_loss_metrics)\n",
        "        val_metrics.append(val_loss_metrics)\n",
        "        pretty_print_metrics(fold, epoch, optimizer, \n",
        "                             train_loss_metrics, val_loss_metrics)\n",
        "        \n",
        "        if val_loss_metrics['lwlrap'] > best_val_metric:\n",
        "            print(f\"    LWLRAP Improved from {best_val_metric} --> {val_loss_metrics['lwlrap']}\\n\")\n",
        "            torch.save(teacher_model.state_dict(), \n",
        "                       os.path.join(config.save_path, f'fold-{fold}.bin'))\n",
        "            best_val_metric = val_loss_metrics['lwlrap']\n",
        "    \n",
        "\n",
        "\n",
        "df = get_n_fold_df(config.train_tp_csv)\n",
        "for fold in range(5 if config.train_5_folds else 1):\n",
        "    train(df, fold)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/filters.py:239: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
            "  \"Empty filters detected in mel frequency basis. \"\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/56 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
            "  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:24.6933:   0%|          | 0/56 [00:11<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:24.6933:   2%|▏         | 1/56 [00:11<10:44, 11.71s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:18.6050:   2%|▏         | 1/56 [00:12<10:44, 11.71s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:18.6050:   4%|▎         | 2/56 [00:12<07:43,  8.58s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:15.2167:   4%|▎         | 2/56 [00:14<07:43,  8.58s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:15.2167:   5%|▌         | 3/56 [00:14<05:38,  6.39s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:13.3097:   5%|▌         | 3/56 [00:15<05:38,  6.39s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:13.3097:   7%|▋         | 4/56 [00:15<04:13,  4.87s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:12.0600:   7%|▋         | 4/56 [00:21<04:13,  4.87s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:12.0600:   9%|▉         | 5/56 [00:21<04:28,  5.26s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:11.2761:   9%|▉         | 5/56 [00:23<04:28,  5.26s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:11.2761:  11%|█         | 6/56 [00:23<03:23,  4.07s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:10.6771:  11%|█         | 6/56 [00:24<03:23,  4.07s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:10.6771:  12%|█▎        | 7/56 [00:24<02:38,  3.23s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:10.2636:  12%|█▎        | 7/56 [00:25<02:38,  3.23s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:10.2636:  14%|█▍        | 8/56 [00:25<02:07,  2.65s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:9.9470:  14%|█▍        | 8/56 [00:32<02:07,  2.65s/it] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:9.9470:  16%|█▌        | 9/56 [00:32<03:00,  3.83s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:9.7124:  16%|█▌        | 9/56 [00:33<03:00,  3.83s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:9.7124:  18%|█▊        | 10/56 [00:33<02:21,  3.07s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:9.5414:  18%|█▊        | 10/56 [00:34<02:21,  3.07s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:9.5414:  20%|█▉        | 11/56 [00:34<01:54,  2.54s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:9.4008:  20%|█▉        | 11/56 [00:36<01:54,  2.54s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:9.4008:  21%|██▏       | 12/56 [00:36<01:35,  2.17s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:9.2381:  21%|██▏       | 12/56 [00:42<01:35,  2.17s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:9.2381:  23%|██▎       | 13/56 [00:42<02:22,  3.32s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:9.1177:  23%|██▎       | 13/56 [00:43<02:22,  3.32s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:9.1177:  25%|██▌       | 14/56 [00:43<01:53,  2.71s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:9.0211:  25%|██▌       | 14/56 [00:44<01:53,  2.71s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:9.0211:  27%|██▋       | 15/56 [00:44<01:33,  2.29s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:8.9251:  27%|██▋       | 15/56 [00:46<01:33,  2.29s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:8.9251:  29%|██▊       | 16/56 [00:46<01:19,  1.99s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:8.8379:  29%|██▊       | 16/56 [00:51<01:19,  1.99s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:8.8379:  30%|███       | 17/56 [00:51<02:01,  3.11s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:8.7766:  30%|███       | 17/56 [00:53<02:01,  3.11s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:8.7766:  32%|███▏      | 18/56 [00:53<01:37,  2.57s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:8.6732:  32%|███▏      | 18/56 [00:54<01:37,  2.57s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:8.6732:  34%|███▍      | 19/56 [00:54<01:20,  2.19s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:8.5744:  34%|███▍      | 19/56 [00:55<01:20,  2.19s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:8.5744:  36%|███▌      | 20/56 [00:55<01:09,  1.93s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:8.5255:  36%|███▌      | 20/56 [01:02<01:09,  1.93s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:8.5255:  38%|███▊      | 21/56 [01:02<01:54,  3.26s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:8.4500:  38%|███▊      | 21/56 [01:03<01:54,  3.26s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:8.4500:  39%|███▉      | 22/56 [01:03<01:31,  2.68s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:8.3900:  39%|███▉      | 22/56 [01:04<01:31,  2.68s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:8.3900:  41%|████      | 23/56 [01:04<01:14,  2.27s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:8.3277:  41%|████      | 23/56 [01:05<01:14,  2.27s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:8.3277:  43%|████▎     | 24/56 [01:05<01:03,  1.98s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:8.2746:  43%|████▎     | 24/56 [01:12<01:03,  1.98s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:8.2746:  45%|████▍     | 25/56 [01:12<01:44,  3.37s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:8.2252:  45%|████▍     | 25/56 [01:13<01:44,  3.37s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:8.2252:  46%|████▋     | 26/56 [01:13<01:22,  2.75s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:8.1918:  46%|████▋     | 26/56 [01:15<01:22,  2.75s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:8.1918:  48%|████▊     | 27/56 [01:15<01:07,  2.32s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:8.1400:  48%|████▊     | 27/56 [01:16<01:07,  2.32s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:8.1400:  50%|█████     | 28/56 [01:16<00:56,  2.02s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:8.1035:  50%|█████     | 28/56 [01:22<00:56,  2.02s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:8.1035:  52%|█████▏    | 29/56 [01:22<01:30,  3.34s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:8.0755:  52%|█████▏    | 29/56 [01:24<01:30,  3.34s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:8.0755:  54%|█████▎    | 30/56 [01:24<01:10,  2.72s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:8.0276:  54%|█████▎    | 30/56 [01:25<01:10,  2.72s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:8.0276:  55%|█████▌    | 31/56 [01:25<00:57,  2.30s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:8.0093:  55%|█████▌    | 31/56 [01:26<00:57,  2.30s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:8.0093:  57%|█████▋    | 32/56 [01:26<00:48,  2.00s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:7.9672:  57%|█████▋    | 32/56 [01:33<00:48,  2.00s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:7.9672:  59%|█████▉    | 33/56 [01:33<01:19,  3.48s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:7.9431:  59%|█████▉    | 33/56 [01:35<01:19,  3.48s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:7.9431:  61%|██████    | 34/56 [01:35<01:01,  2.82s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:7.9195:  61%|██████    | 34/56 [01:36<01:01,  2.82s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:7.9195:  62%|██████▎   | 35/56 [01:36<00:49,  2.36s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:7.8967:  62%|██████▎   | 35/56 [01:37<00:49,  2.36s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:7.8967:  64%|██████▍   | 36/56 [01:37<00:40,  2.04s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:7.8670:  64%|██████▍   | 36/56 [01:44<00:40,  2.04s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:7.8670:  66%|██████▌   | 37/56 [01:44<01:05,  3.44s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:7.8484:  66%|██████▌   | 37/56 [01:45<01:05,  3.44s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:7.8484:  68%|██████▊   | 38/56 [01:45<00:50,  2.81s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:7.8118:  68%|██████▊   | 38/56 [01:46<00:50,  2.81s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:7.8118:  70%|██████▉   | 39/56 [01:46<00:40,  2.36s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:7.7850:  70%|██████▉   | 39/56 [01:48<00:40,  2.36s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:7.7850:  71%|███████▏  | 40/56 [01:48<00:32,  2.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:7.7518:  71%|███████▏  | 40/56 [01:54<00:32,  2.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:7.7518:  73%|███████▎  | 41/56 [01:54<00:50,  3.36s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:7.7202:  73%|███████▎  | 41/56 [01:56<00:50,  3.36s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:7.7202:  75%|███████▌  | 42/56 [01:56<00:38,  2.75s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:7.7034:  75%|███████▌  | 42/56 [01:57<00:38,  2.75s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:7.7034:  77%|███████▋  | 43/56 [01:57<00:30,  2.33s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:7.6740:  77%|███████▋  | 43/56 [01:58<00:30,  2.33s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:7.6740:  79%|███████▊  | 44/56 [01:58<00:24,  2.03s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:7.6493:  79%|███████▊  | 44/56 [02:04<00:24,  2.03s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:7.6493:  80%|████████  | 45/56 [02:04<00:35,  3.20s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:7.6384:  80%|████████  | 45/56 [02:05<00:35,  3.20s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:7.6384:  82%|████████▏ | 46/56 [02:05<00:26,  2.62s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:7.6177:  82%|████████▏ | 46/56 [02:07<00:26,  2.62s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:7.6177:  84%|████████▍ | 47/56 [02:07<00:20,  2.24s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:7.5916:  84%|████████▍ | 47/56 [02:08<00:20,  2.24s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:7.5916:  86%|████████▌ | 48/56 [02:08<00:15,  1.98s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:7.5790:  86%|████████▌ | 48/56 [02:14<00:15,  1.98s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:7.5790:  88%|████████▊ | 49/56 [02:14<00:21,  3.10s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:7.5609:  88%|████████▊ | 49/56 [02:15<00:21,  3.10s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:7.5609:  89%|████████▉ | 50/56 [02:15<00:15,  2.57s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:7.5430:  89%|████████▉ | 50/56 [02:17<00:15,  2.57s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:7.5430:  91%|█████████ | 51/56 [02:17<00:11,  2.21s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:7.5204:  91%|█████████ | 51/56 [02:18<00:11,  2.21s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:7.5204:  93%|█████████▎| 52/56 [02:18<00:07,  1.95s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:7.5084:  93%|█████████▎| 52/56 [02:23<00:07,  1.95s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:7.5084:  95%|█████████▍| 53/56 [02:23<00:09,  3.03s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:7.4880:  95%|█████████▍| 53/56 [02:25<00:09,  3.03s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:7.4880:  96%|█████████▋| 54/56 [02:25<00:05,  2.50s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:7.4685:  96%|█████████▋| 54/56 [02:26<00:05,  2.50s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:7.4685:  98%|█████████▊| 55/56 [02:26<00:02,  2.13s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:7.4462:  98%|█████████▊| 55/56 [02:27<00:02,  2.13s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:7.4462: 100%|██████████| 56/56 [02:27<00:00,  2.64s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:6.8544:   0%|          | 0/14 [00:11<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:6.8544:   7%|▋         | 1/14 [00:11<02:32, 11.70s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:6.9054:   7%|▋         | 1/14 [00:12<02:32, 11.70s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:6.9054:  14%|█▍        | 2/14 [00:12<01:40,  8.41s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:6.8166:  14%|█▍        | 2/14 [00:13<01:40,  8.41s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:6.8166:  21%|██▏       | 3/14 [00:13<01:07,  6.12s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:6.6901:  21%|██▏       | 3/14 [00:13<01:07,  6.12s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:6.6901:  29%|██▊       | 4/14 [00:13<00:45,  4.51s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:6.6091:  29%|██▊       | 4/14 [00:21<00:45,  4.51s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:6.6091:  36%|███▌      | 5/14 [00:21<00:48,  5.35s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:6.6256:  36%|███▌      | 5/14 [00:22<00:48,  5.35s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:6.6256:  43%|████▎     | 6/14 [00:22<00:31,  3.97s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:6.5088:  43%|████▎     | 6/14 [00:22<00:31,  3.97s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:6.5088:  50%|█████     | 7/14 [00:22<00:21,  3.00s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:6.5027:  50%|█████     | 7/14 [00:23<00:21,  3.00s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:6.5027:  57%|█████▋    | 8/14 [00:23<00:13,  2.33s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:6.5343:  57%|█████▋    | 8/14 [00:30<00:13,  2.33s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:6.5343:  64%|██████▍   | 9/14 [00:30<00:18,  3.61s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:6.6386:  64%|██████▍   | 9/14 [00:30<00:18,  3.61s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:6.6386:  71%|███████▏  | 10/14 [00:30<00:10,  2.75s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:6.6237:  71%|███████▏  | 10/14 [00:31<00:10,  2.75s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:6.6237:  79%|███████▊  | 11/14 [00:31<00:06,  2.14s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:6.6473:  79%|███████▊  | 11/14 [00:32<00:06,  2.14s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:6.6473:  86%|████████▌ | 12/14 [00:32<00:03,  1.72s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:6.5808:  86%|████████▌ | 12/14 [00:37<00:03,  1.72s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:6.5808:  93%|█████████▎| 13/14 [00:37<00:02,  2.71s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:6.5270:  93%|█████████▎| 13/14 [00:38<00:02,  2.71s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:0 - Loss:6.5270: 100%|██████████| 14/14 [00:38<00:00,  2.73s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "    Fri Feb  5 18:44:02 2021 \n",
            "\n",
            "    Fold:0, Epoch:0, LR:0.0009960574, Cons. Weight: 0.6737946999085467\n",
            "\n",
            "    --------------------------------------------------------\n",
            "    Metric:              Train    |   Val\n",
            "    --------------------------------------------------------\n",
            "    Loss:                7.4462   |   6.5270\n",
            "\n",
            "    LWLRAP:              0.2156   |   0.2930\n",
            "\n",
            "    Class Loss:          7.4400   |   6.5224\n",
            "\n",
            "    Consistency Loss:    0.0062   |   0.0046\n",
            "\n",
            "    --------------------------------------------------------\n",
            "\n",
            "    \n",
            "    LWLRAP Improved from -inf --> 0.2929901322273667\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/56 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:1 - Loss:5.9719:   0%|          | 0/56 [00:10<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:1 - Loss:5.9719:   2%|▏         | 1/56 [00:10<09:24, 10.25s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:1 - Loss:6.0764:   2%|▏         | 1/56 [00:11<09:24, 10.25s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:1 - Loss:6.0764:   4%|▎         | 2/56 [00:11<06:48,  7.57s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:1 - Loss:6.2390:   4%|▎         | 2/56 [00:12<06:48,  7.57s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:1 - Loss:6.2390:   5%|▌         | 3/56 [00:12<05:02,  5.70s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:1 - Loss:6.3601:   5%|▌         | 3/56 [00:14<05:02,  5.70s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:1 - Loss:6.3601:   7%|▋         | 4/56 [00:14<03:48,  4.39s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:1 - Loss:6.2616:   7%|▋         | 4/56 [00:20<03:48,  4.39s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:1 - Loss:6.2616:   9%|▉         | 5/56 [00:20<04:13,  4.96s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:1 - Loss:6.3208:   9%|▉         | 5/56 [00:21<04:13,  4.96s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:1 - Loss:6.3208:  11%|█         | 6/56 [00:21<03:13,  3.86s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:1 - Loss:6.3427:  11%|█         | 6/56 [00:23<03:13,  3.86s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:1 - Loss:6.3427:  12%|█▎        | 7/56 [00:23<02:32,  3.11s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:1 - Loss:6.3086:  12%|█▎        | 7/56 [00:24<02:32,  3.11s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:1 - Loss:6.3086:  14%|█▍        | 8/56 [00:24<02:03,  2.58s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:1 - Loss:6.2538:  14%|█▍        | 8/56 [00:30<02:03,  2.58s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:1 - Loss:6.2538:  16%|█▌        | 9/56 [00:30<02:45,  3.53s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:1 - Loss:6.2981:  16%|█▌        | 9/56 [00:31<02:45,  3.53s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch:1 - Loss:6.2981:  18%|█▊        | 10/56 [00:31<02:11,  2.86s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmI6-eTplWZq"
      },
      "source": [
        "# Predict on Test Set\n",
        "We'll predict using the teacher model but you could also use the student or a combination of the two. Inference works just like it would for a vanilla baseline model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9Sbo59_lWZr"
      },
      "source": [
        "def test(test_df, train_fold):\n",
        "    test_dataset = TestDataset(\n",
        "        df=test_df,\n",
        "        data_path=GCS_DS_PATH+\"/test\",\n",
        "        period=config.period,\n",
        "        step=config.step\n",
        "    )\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=1,\n",
        "        shuffle=False,\n",
        "        drop_last=False,\n",
        "        num_workers=config.num_workers\n",
        "    )\n",
        "    \n",
        "    weights_path = os.path.join(config.save_path, f'fold-{train_fold}.bin')\n",
        "    model = get_model()\n",
        "    model.load_state_dict(torch.load(weights_path, map_location=config.device), strict=False)\n",
        "    \n",
        "    test_pred, ids = predict_on_test(model, test_loader)\n",
        "\n",
        "    # Build Submission File\n",
        "    test_pred_df = pd.DataFrame({\n",
        "        \"recording_id\": test_df.recording_id.values\n",
        "    })\n",
        "    target_cols = test_df.columns[1:].values.tolist()\n",
        "    test_pred_df = test_pred_df.join(pd.DataFrame(np.array(test_pred), \n",
        "                                                  columns=target_cols))\n",
        "    test_pred_df.to_csv(os.path.join(config.save_path, \n",
        "                                     f\"fold-{train_fold}-submission.csv\"), \n",
        "                        index=False)\n",
        "    \n",
        "    \n",
        "test_df = pd.read_csv(config.test_csv)\n",
        "for fold in range(5 if config.train_5_folds else 1):\n",
        "    test(test_df, fold)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bC2gszlxlWZr"
      },
      "source": [
        "## 5 Fold Ensemble\n",
        "For 5 fold runs, we'll create a single ensemble prediction by simply averaging all of the folds."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NyEN_dZlWZr"
      },
      "source": [
        "def ensemble(submission_path):\n",
        "    dfs = [pd.read_csv(os.path.join(\n",
        "        config.save_path, f\"fold-{i}-submission.csv\")) for i in range(5)]\n",
        "    anchor = dfs[0].copy()\n",
        "    cols = anchor.columns[1:]\n",
        "   \n",
        "    for c in cols:\n",
        "        total = 0\n",
        "        for df in dfs:\n",
        "            total += df[c]\n",
        "        anchor[c] = total / len(dfs)\n",
        "    anchor.to_csv(submission_path, index=False)\n",
        "\n",
        "\n",
        "submission_path = os.path.join(config.save_path, f\"submission.csv\")\n",
        "if config.train_5_folds:\n",
        "    ensemble(submission_path)\n",
        "else:\n",
        "    fold0_submission = os.path.join(config.save_path, f\"fold-0-submission.csv\")\n",
        "    os.rename(fold0_submission, submission_path)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCGmltD1lWZr"
      },
      "source": [
        "# Conclusion \n",
        "Thanks for reading! I dropped some unrelated tricks from this and didn't spend much time tuning so there's almost definetely room for improvement.\n",
        "\n",
        "I know it's pretty late in the competition for new notebooks, but considering that there are a few other public notebooks that score higher, I'm hoping this won't cause a significant shakeup. "
      ]
    }
  ]
}